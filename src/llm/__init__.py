"""
LLM Module - Ollama client for local inference with Gemma3:4B.
"""
from .ollama_client import OllamaClient

__all__ = ["OllamaClient"]
